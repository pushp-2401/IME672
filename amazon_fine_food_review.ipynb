{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "amazon_fine_food_review",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMsNqYZPT/J9X9N5kOcMoA4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushp-2401/IME672/blob/main/amazon_fine_food_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2TI_dfeJBlp"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLzZmJ8iJH6Z"
      },
      "source": [
        "con = sqlite3.connect('database.sqlite') \n",
        "\n",
        "#filtering only positive and negative reviews i.e. \n",
        "# not taking into consideration those reviews with Score=3\n",
        "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3\"\"\", con) \n",
        "\n",
        "\n",
        "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
        "def partition(x):\n",
        "    if x < 3:\n",
        "        return 'negative'\n",
        "    return 'positive'\n",
        "\n",
        "#changing reviews with score less than 3 to be positive and vice-versa\n",
        "actualScore = filtered_data['Score']\n",
        "positiveNegative = actualScore.map(partition) \n",
        "filtered_data['Score'] = positiveNegative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "genaB3VVJXQM"
      },
      "source": [
        "print(filtered_data.shape) #looking at the number of attributes and size of the data\n",
        "filtered_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXJ2gyk2JeAk"
      },
      "source": [
        "display= pd.read_sql_query(\"\"\"\n",
        "SELECT *\n",
        "FROM Reviews\n",
        "WHERE Score != 3 AND UserId=\"AR5J8UI46CURR\"\n",
        "ORDER BY ProductID\n",
        "\"\"\", con)\n",
        "display.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51iMitMPJhsu"
      },
      "source": [
        "#Sorting data according to ProductId in ascending order\n",
        "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3wtyD9aJiaZ"
      },
      "source": [
        "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
        "final.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA5G-KHtJkw6"
      },
      "source": [
        "(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iESC7epZJqbo"
      },
      "source": [
        "display= pd.read_sql_query(\"\"\"\n",
        "SELECT *\n",
        "FROM Reviews\n",
        "WHERE Score != 3 AND Id=44737 OR Id=64422\n",
        "ORDER BY ProductID\n",
        "\"\"\", con)\n",
        "\n",
        "display.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oInG18ZSJuNC"
      },
      "source": [
        "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkEMdEo2JySK"
      },
      "source": [
        "final['Score'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu3iY-nAJ2De"
      },
      "source": [
        "import re\n",
        "i=0;\n",
        "for sent in final['Text'].values:\n",
        "    if (len(re.findall('<.*?>', sent))):\n",
        "        print(i)\n",
        "        print(sent)\n",
        "        break;\n",
        "    i += 1;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9z_-fsHJ50S"
      },
      "source": [
        "stop = set(stopwords.words('english')) #set of stopwords\n",
        "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
        "\n",
        "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, ' ', sentence)\n",
        "    return cleantext\n",
        "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    return  cleaned\n",
        "print(stop)\n",
        "print('************************************')\n",
        "print(sno.stem('tasty'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjpPc0hgJ9ov"
      },
      "source": [
        "i=0\n",
        "str1=' '\n",
        "final_string=[]\n",
        "all_positive_words=[] # store words from +ve reviews here\n",
        "all_negative_words=[] # store words from -ve reviews here.\n",
        "s=''\n",
        "for sent in final['Text'].values:\n",
        "    filtered_sentence=[]\n",
        "    #print(sent);\n",
        "    sent=cleanhtml(sent) # remove HTMl tags\n",
        "    for w in sent.split():\n",
        "        for cleaned_words in cleanpunc(w).split():\n",
        "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
        "                if(cleaned_words.lower() not in stop):\n",
        "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
        "                    filtered_sentence.append(s)\n",
        "                    if (final['Score'].values)[i] == 'positive': \n",
        "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
        "                    if(final['Score'].values)[i] == 'negative':\n",
        "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
        "                else:\n",
        "                    continue\n",
        "            else:\n",
        "                continue \n",
        "    #print(filtered_sentence)\n",
        "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
        "    #print(\"***********************************************************************\")\n",
        "    \n",
        "    final_string.append(str1)\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2c59ATpKHry"
      },
      "source": [
        "final['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review \n",
        "final['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZBkDlLvKLGX"
      },
      "source": [
        "final.head(3) #below the processed review can be seen in the CleanedText Column \n",
        "# store final table into an SQlLite table for future.\n",
        "conn = sqlite3.connect('final.sqlite')\n",
        "c=conn.cursor()\n",
        "conn.text_factory = str\n",
        "final.to_sql('Reviews', conn,  schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_IuI82VKOEb"
      },
      "source": [
        "final=final.sort_values(by=['Time'],ascending=False)\n",
        "finalDataPoints=final\n",
        "\n",
        "x=finalDataPoints[\"CleanedText\"]\n",
        "y=finalDataPoints[\"Score\"]\n",
        "\n",
        "\n",
        "\n",
        "final = pd.DataFrame( { \"Score\":y, \"Text\": x } )\n",
        "final.head(5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbZJLmxMKTBH"
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "ax = sns.countplot(x=\"Score\", data=final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI4KFD52KZfE"
      },
      "source": [
        "value_count=final['Score'].value_counts()\n",
        "print(\"{}% data having positive reviews\".format(round(value_count[0]/final.shape[0]*100,2)))\n",
        "print(\"{}% data having negative reviews\".format(round(value_count[1]/final.shape[0]*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm-i00c5KdA-"
      },
      "source": [
        "bow = CountVectorizer()\n",
        "x_unigram = bow.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fJMPh1kKhP2"
      },
      "source": [
        "std_data = StandardScaler(with_mean = False).fit_transform(x_unigram)\n",
        "std_data.shape\n",
        "#std_data is sparcematrix making it a densematrix T-SNE cannot be apply on sparse matrix\n",
        "std_data = std_data.todense()\n",
        "\n",
        "#plotting TSNE\n",
        "model = TSNE(n_components=2, random_state=0, perplexity = 30)\n",
        "tsne_data = model.fit_transform(std_data)\n",
        "\n",
        "\n",
        "# creating a new data frame which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, finaldatapointscore)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"dim1\", \"dim2\", \"score\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sns.FacetGrid(tsne_df, hue=\"score\", size=6).map(plt.scatter, 'dim1', 'dim2').add_legend()\n",
        "plt.title(\"TSNE for Bag of Words\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZBB-Bm6Kkp4"
      },
      "source": [
        "bi_gram = CountVectorizer(ngram_range=(1,2))\n",
        "x_bigram = bi_gram.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGh0Tj2HKoeB"
      },
      "source": [
        "#standardization of finalDataPoints\n",
        "std_data = StandardScaler(with_mean = False).fit_transform(x_bigram)\n",
        "std_data.shape\n",
        "#std_data is sparcematrix making it a densematrix T-SNE cannot be apply on sparse matrix\n",
        "std_data = std_data.todense()\n",
        "\n",
        "#plotting TSNE\n",
        "model = TSNE(n_components=2, random_state=0, perplexity = 30)\n",
        "tsne_data = model.fit_transform(std_data)\n",
        "\n",
        "\n",
        "# creating a new data frame which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, finaldatapointscore)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"dim1\", \"dim2\", \"score\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sns.FacetGrid(tsne_df, hue=\"score\", size=6).map(plt.scatter, 'dim1', 'dim2').add_legend()\n",
        "plt.title(\"TSNE for Bag of Words\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG5CM0SfKrMZ"
      },
      "source": [
        "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
        "x_tfidf = tf_idf_vect.fit_transform(x)\n",
        "\n",
        "\n",
        "\n",
        "#standardization of finalDataPoints\n",
        "std_data = StandardScaler(with_mean = False).fit_transform(x_tfidf)\n",
        "std_data.shape\n",
        "#std_data is sparcematrix making it a densematrix T-SNE cannot be apply on sparse matrix\n",
        "std_data = std_data.todense()\n",
        "\n",
        "#plotting TSNE\n",
        "model = TSNE(n_components=2, random_state=0, perplexity = 30)\n",
        "tsne_data = model.fit_transform(std_data)\n",
        "\n",
        "\n",
        "# creating a new data frame which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, finaldatapointscore)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"dim1\", \"dim2\", \"score\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sns.FacetGrid(tsne_df, hue=\"score\", size=6).map(plt.scatter, 'dim1', 'dim2').add_legend()\n",
        "plt.title(\"TSNE for Bag of Words\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33O85G7rKxvi"
      },
      "source": [
        "i=0\n",
        "list_of_sent=[]\n",
        "for sent in x:\n",
        "    list_of_sent.append(sent.split())\n",
        "\n",
        "\n",
        "\n",
        "w2v_model=Word2Vec(list_of_sent,min_count=5,size=50, workers=4)\n",
        "\n",
        "\n",
        "\n",
        "w2v_words = list(w2v_model.wv.vocab)\n",
        "print(\"number of words that occured minimum 5 times \",len(w2v_words))\n",
        "print(\"sample words \", w2v_words[0:50])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhvSI1xEK5TS"
      },
      "source": [
        "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
        "for sent in list_of_sent: # for each review/sentence\n",
        "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
        "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
        "    for word in sent: # for each word in a review/sentence\n",
        "        if word in w2v_words:\n",
        "            vec = w2v_model.wv[word]\n",
        "            sent_vec += vec\n",
        "            cnt_words += 1\n",
        "    if cnt_words != 0:\n",
        "        sent_vec /= cnt_words\n",
        "    sent_vectors.append(sent_vec)\n",
        "print(len(sent_vectors))\n",
        "print(len(sent_vectors[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eE9nBi2K9_K"
      },
      "source": [
        "sent_vectors\n",
        "\n",
        "\n",
        "\n",
        "model = TSNE(n_components = 2, perplexity = 30)\n",
        "tsne_data = model.fit_transform(sent_vectors)\n",
        "\n",
        "tsne_data = np.vstack((tsne_data.T, finaldatapointscore)).T\n",
        "tsne_df = pd.DataFrame(data = tsne_data, columns = (\"dim1\", \"dim2\", \"score\"))\n",
        "sns.FacetGrid(tsne_df, hue = \"score\", size = 6).map(plt.scatter, \"dim1\", \"dim2\").add_legend()\n",
        "plt.title(\"TSNE for TF-IDF\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SvvMLm8LD8f"
      },
      "source": [
        "tf_idf_vect = TfidfVectorizer()\n",
        "final_tf_idf = tf_idf_vect.fit_transform(x)\n",
        "dictionary = dict(zip(tf_idf_vect.get_feature_names(), list(tf_idf_vect.idf_)))\n",
        "\n",
        "\n",
        "\n",
        "# TF-IDF weighted Word2Vec\n",
        "tfidf_feat = tf_idf_vect.get_feature_names() # tfidf words/col-names\n",
        "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
        "\n",
        "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
        "row=0;\n",
        "for sent in tqdm(list_of_sent): # for each review/sentence \n",
        "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
        "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
        "    for word in sent: # for each word in a review/sentence\n",
        "        if word in w2v_words:\n",
        "            vec = w2v_model.wv[word]\n",
        "            tf_idf = dictionary[word]*sent.count(word)\n",
        "            sent_vec += (vec * tf_idf)\n",
        "            weight_sum += tf_idf\n",
        "    if weight_sum != 0:\n",
        "        sent_vec /= weight_sum\n",
        "    tfidf_sent_vectors.append(sent_vec)\n",
        "    row += 1\n",
        "\n",
        "\n",
        "\n",
        "tfidf_sent_vectors\n",
        "\n",
        "\n",
        "\n",
        "tsne_data = model.fit_transform(tfidf_sent_vectors)\n",
        "\n",
        "tsne_data = np.vstack((tsne_data.T, finaldatapointscore)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"dim1\", \"dim2\", \"score\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sns.FacetGrid(tsne_df, hue=\"score\", size=6).map(plt.scatter, 'dim1', 'dim2').add_legend()\n",
        "plt.title(\"TSNE for TF-IDF Word2vec\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulOXKCdaLNHO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}